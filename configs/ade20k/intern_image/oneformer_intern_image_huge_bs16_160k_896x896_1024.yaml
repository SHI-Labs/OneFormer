_BASE_: ../oneformer_R50_bs16_160k.yaml
MODEL:
  BACKBONE:
    NAME: "D2InternImage"
  SEM_SEG_HEAD:
    CONVS_DIM: 1024
    MASK_DIM: 1024
  INTERNIMAGE:
    CHANNELS: 320
    DEPTHS: [6, 6, 32, 6]
    GROUPS: [10, 20, 40, 80]
    WITH_CP: True
    MLP_RATIO: 4.0
    DW_KERNEL_SIZE: 5
    LEVEL2_POST_NORM_BLOCK_IDS: [5, 11, 17, 23, 29]
  WEIGHTS: "internimage_h_jointto22k_384.pkl"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  ONE_FORMER:
    HIDDEN_DIM: 1024
    NUM_OBJECT_QUERIES: 250
    NHEADS: 32
    DIM_FEEDFORWARD: 4096
  TEXT_ENCODER:
    WIDTH: 1024
    CONTEXT_LENGTH: 77
    N_CTX: 16
INPUT:
  MIN_SIZE_TRAIN: !!python/object/apply:eval ["[int(x * 0.1 * 896) for x in range(5, 21)]"]
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 896
  MAX_SIZE_TRAIN: 3584
  MAX_SIZE_TEST: 3584
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (896, 896)
    SINGLE_CATEGORY_MAX_AREA: 1.0
  COLOR_AUG_SSD: True
  SIZE_DIVISIBILITY: 896  # used in dataset mapper
  FORMAT: "RGB"
TEST:
  DETECTIONS_PER_IMAGE: 250
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False
    MIN_SIZES: [448, 678, 896, 1120, 1344, 1568]
    MAX_SIZE: 6272
    FLIP: True
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.00004
